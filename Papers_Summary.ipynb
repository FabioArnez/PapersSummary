{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety Verification for Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Safety Verification for Deep Neural Networks with Provable Guarantees\n",
    "__Author__: Marta Z. Kwiatkowska\n",
    "\n",
    "__Date__: 08/2019\n",
    "\n",
    "This paper provides a brief overview of existing research directions aimed at improving safety and robustness of neural networks:\n",
    "\n",
    "- Automated Verification Methods\n",
    "- Probabilistic Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Given the complexity of the scenarios and uncertainty in the environment, it is important to ensure that software incorporating machine learning components is robust and safe.\n",
    "- Robustness (or resilience) of neural networks to adversarial perturbations is an active topic of investigation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Automated verification Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Verification approaces aim to provide _formal guarantees_ to the robustness of DNNs.\n",
    "\n",
    "- Several approaches analyse the robustness of neural networks by considering the maximal size of the perturbation that will not cause a misclassification.\n",
    "\n",
    "- For a given input point, the maximal safe radius is defined as the largest radius centered on that point within which no adversarial examples exist.\n",
    "\n",
    "- Solution methods include encoding as a set of constraints and reduction to satisfiability or optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Probabilistic Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Previous works above assume a trained network with fixed weights and therefore yield deterministic robustness guarantees.\n",
    "\n",
    "Neural networks have a natural probabilistic interpretation, they lend themselves to frameworks for computing probabilistic guarantees on their robustness. \n",
    "\n",
    "- Bayesian neural networks (BNNs) are neural networks with distributions over their weights, which can capture the uncertainty within the learning model\n",
    "- The neural network can thus return an uncertainty estimate along with the output, which is important for safety-critical applications\n",
    "-  Probabilistic robustness is considered for BNNs, using a probabilistic generalization of the usual statement of (deterministic) robustness to adversarial examples, namely the computation of the probability (induced by the distribution over the BNN weights) of the classification being invariant over the neighborhood around a given input point.\n",
    "- Since the computation of the posterior probability for a BNN is intractable, the method employs statistical model checking (SMC), based on based on the observation that each sample taken from the (possibly approximate) posterior weight distribution of the BNN induces a deterministic neural network.\n",
    "\n",
    "A related safety and robustness verification approach, which offers formal guarantees, has also been developed for Gaussian process (GP) models, for regression and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In contrast to DNNs, where trade offs between robustness and accuracy have been observed [11, 3], robustness of GPs increases with training. More research is needed to explore these phenomena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Statistical Guarantees for the Robustness of Bayesian Neural Networks\n",
    "\n",
    "__Author__: Luca Cardelli , Marta Kwiatkowska , Luca Laurenti , Nicola Paoletti ,Andrea Patane and Matthew Wicker\n",
    "\n",
    "__Date__: 05/03/2019\n",
    "\n",
    "\n",
    "__Contribution__:\n",
    "\n",
    "- Building on statistical verification techniques for probabilistic models, we develop a framework that allows us to estimate probabilistic robustness for a BNN with statistical guarantees, i.e., with a __*priori*__ error and confidence bounds.\n",
    "- Present a statistical framework to evaluate the probabilistic robustness of a BNN\n",
    "- This is particularly important in safety-critical applications, where uncertainty estimates can be propagated through the decision pipeline to enable safe decision making\n",
    "\n",
    "\n",
    "__Conclusion__:\n",
    "\n",
    "- We introduced probabilistic robustness for BNNs that takes into account both model and data uncertainty, and can be used to capture, among other properties, the probability of the existence of adversarial examples.\n",
    "- Developed a sequential scheme to estimate such a probability with a __*priori*__ statistical guarantees on the estimation error and confidence and evaluated it on fully connected and convolutional networks.\n",
    "- Their work represents an important step towards the application of neural networks in safety-critical applications.\n",
    "\n",
    "\n",
    "\n",
    "__Important Remarks__:\n",
    "\n",
    "- Various approximation methods have been investigated to perform inference with BNNs in practice.\n",
    "    - HMC, VI $\\rightarrow$ Bayes by Backpropagation, Montecarlo Dropout\n",
    "- for HMC and VI (respectively second and third column of the figure) we observe smooth changes in the robustness probability w.r.t. ε and δ, where these changes are quantitatively more prominent for HMC than for VI. \n",
    "    -  As with HMC no assumption is made on the form of the posterior distribution\n",
    "    - This quantitative robustness difference might suggest that the normality assumption made by VI during training is not sufficient in adversarial settings $\\rightarrow$ as the model is pushed toward corner-case scenarios\n",
    "    - This could make BNN vulnerable to low-variance adversarial examples.\n",
    "- MCD is characterised by an almost deterministic behaviour with respect to Problem 1, with estimated robustness probabilities sharply moving from 1 to 0.\n",
    "    - May be due to the fact that, in adversarial settings, the MCD approximation could lead to an underestimation of model uncertainty. Underestimation of the uncertainty for MCD has also been observed in non-adversarial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- A wide variety of formal verification methods have been developed for deterministic NNs.\n",
    "- Only methods based on pointwise uncertainty computation have been proposed for BNNs.\n",
    "- There are no methods directed at providing guarantees on BNNs that fully take into account their probabilistic nature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Uncertainty Quantification with Statistical Guarantees in End-to-End Autonomous Driving\n",
    "\n",
    "__Authors__: Rhiannon Michelmore, Matthew Wicker, Luca Laurenti, Luca Cardelli, Yarin Gal, Marta Kwiatkowska\n",
    "\n",
    "__Date__: 21/09/2019\n",
    "\n",
    "__Contribution:__\n",
    "\n",
    "- In this paper we develop a novel framework for evaluating the safety of autonomous driving using end-to-end BNN controllers, that is, controllers in which the end-to-end process, from sensors to actuation, involves a single BNN without modularization.\n",
    "- We demonstrate how to obtain __*a priori statistical guarantees*__ on the safety of the application of the BNN in a given scenario.\n",
    "- We consider both probabilistic safety, which is the probability that the controller will keep the car safe for a given time horizon, and real-time decision confidence, which is the probability that the BNN is certain of a given decision.\n",
    "- By using concentration inequalities, such as Chernoff bounds, we show that both measures can be estimated with arbitrarily stringent __*a priori guarantees*__.\n",
    "\n",
    "\n",
    "__Conclusion:__\n",
    "\n",
    "- We presented a framework for evaluating the safety of end-to-end BNN controllers for self-driving cars, which allows one to obtain uncertainty estimates for the controller's decisions with __*a priori statistical guarantees*__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Paper Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- DNN controllers for autonomous driving have recently benefited from significant performance improvements, and have begun deployment in the real world. \n",
    "- Safety guarantees are needed on the controller behavior that properly take account of the uncertainty within the model as well as sensor noise\n",
    "- Bayesian neural networks, which assume a prior over the weights, have been shown capable of producing such uncertainty measures, but properties surrounding their safety have not yet been quantified for use in autonomous driving scenarios.\n",
    "- In this paper, we develop a framework based on a state-of-the-art simulator for evaluating end-to-end Bayesian controllers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RunTime Verification Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T11:45:26.677211Z",
     "start_time": "2019-12-09T11:45:26.572031Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Statistical Model Checking Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Common Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. __Runtime Verification__:\n",
    "    - Runtime verification is the discipline of computer science that deals with the study, development, and application of those verification techniques that allow checking whether a run of a system under scrutiny satisfies or violates a given correctness property.\n",
    "    - Deals (only) with detection of violations (or satisfactions) of correcteness properties. Thus, whenevere a vilation has been observed, usually it does not influence or change the program's execution.\n",
    "\n",
    "2. __A Run of a System__:\n",
    "    -  Understood as a possibly infinite sequence of the system's states\n",
    "    - Formally, a run may be considered as a possible infinite word otr trace.\n",
    "\n",
    "\n",
    "3. __An Execution of a System__:\n",
    "    - Is a finite prefix of a run and formally it is a finite trace.\n",
    "    - When running a program we can only observe executions, which however restrict the corresponding evolving run as being in their prefix.\n",
    "\n",
    "\n",
    "4. __Monitors__:\n",
    "    - Is a device that reads a finite trace and yields a certain veredict\n",
    "    - Checks whether an executions meets a correctness property\n",
    "    - Decides whether the current execution satisfies a given correctness property by outputting yes/true or no/false\n",
    "\n",
    "\n",
    "5. __Model Checking__:\n",
    "    - Model checking describes the problem of determining whether a given model $M$ and correctness property $\\phi$, all computations of $M$ satisfy $\\phi$.\n",
    "    - Automatic verificaiton technique\n",
    "    - Usually for finite state systems\n",
    "\n",
    "\n",
    "6. __Runtime Verification__:\n",
    "    - Has its origins in model checking\n",
    "    - Differences with model checking:\n",
    "        - In model Checking all executions of a given system are examined to answer  whether they satisfy a given correctness property $\\phi$\n",
    "        - While model checking typically considers infinite traces, runtime verification deals with finite executions—as execu tions have necessarily to be finite\n",
    "        - While in model checking a complete model is given allowing to consider arbitrary positions of a trace, runtime verification, especially when dealing with online monitoring, considers finite executions of increasing size. For this, a monitor should be designed to consider executions in an incremental fashion.\n",
    "\n",
    "    - __Runtime verification deals only with observed executions as they are generated by the real system.__\n",
    "    - __Thus runtime verification is applicable to black box systems for whichnosystemmodelis at hand.__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "7. __When to Use Runtime Verification__:\n",
    "    - The verification verdict, as obtained by model checking or theorem proving, is often referring to a model of the real system under analysis, since applying these techniques __directly to the real implementation would be intractable.__\n",
    "    - Runtime verification may then be used to easily check the actual execution of he system, to make sure that the implementation really meets its correctness properties.\n",
    "    - Some information is available only at runtime or is conveniently checked at runtime\n",
    "    - The behavior of an application may depend heavily on the environment of the target system, but a precise description of this environment might not exist.\n",
    "    - In the case of safety-critical systems, it is useful also to monitor behavior or properties that have been statically proved or tested, mainly to have a double check that everything goes well:\n",
    "        - Here, runtime verification acts as a partner of theorem proving, model checking and testing.\n",
    "\n",
    "    - The above mentioned items can be found in a combined manner especially in highly dynamic systems such as adaptive, self-organizing, or self-healing systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A Survey of  Statistical Model Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Abstract\n",
    "\n",
    "- Resasoning analytically about the behavior of complex systems is generally infeasible. \n",
    "- Statistical Model Checking addresses this wakness by using a simulation based approach to reason about precise properties specified in stochastic temporal logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Reasoning purely analytically about the behavior of complex stochastic systems is generally __infeasible__\n",
    "- Numerical techniques can provide higher accuracy. However, their computational and memory requirements don't scale well\n",
    "- Numerical techniques require an explicit system description that includes state transition probabilities\n",
    "- An approach based on statistical analysis relies on the ability to obtain sample properties. Such samples can be results of simulations or a system execution\n",
    "- Te statistical approach is applicable even when a system is a __\"black box\"__ whose behavior is not fully understood or controllable.\n",
    "- SMC uses simulation based approaches to reason about precise properties specified in a _stochastic temporal logic_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Example: Properties specified in temporal logic__\n",
    "- Within some time bound, the probability that the number of messages in a queue will be greater than 5 is less than 0.01\n",
    "    - This sort of property may also be informally stated and reasoned about in traditional queuing theory\n",
    "- Or property may be more complex: that in some bounded time period, if a node crashes, the probability that it will recover within 5000 steps is between 0.9 and 0.99\n",
    "- Temporal logics can get richer and allow logical deduction to be combined with statistical techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In SMC, executions of a system are sampled and after statistical inference may be applied:\n",
    "1. Hypothesis Testing\n",
    "   - Extent to which observations \"conform\" to a given specification\n",
    "   \n",
    "2. Estimation\n",
    "    - Determine likely values of parameters based on the assumption tht the data is randomly drawn from a specified type of distribution\n",
    "    \n",
    "\n",
    "__In either case, the results of the inference can be used to evaluate a property specified in a stochastic temporal logic.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
